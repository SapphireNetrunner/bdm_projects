{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVp2sAW2H7hA"
      },
      "source": [
        "# **Project 1 – NYC Taxi Analysis**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE1o6RO_AD-l"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import (\n",
        "    col,\n",
        "    unix_timestamp,\n",
        "    udf,\n",
        "    when,\n",
        "    sum as spark_sum,\n",
        "    count,\n",
        "    avg,\n",
        "    lag,\n",
        "    lit\n",
        ")\n",
        "from pyspark.sql.window import Window\n",
        "from shapely.geometry import shape, Point\n",
        "from pyspark.sql.types import StringType\n",
        "import json\n",
        "\n",
        "spark = SparkSession.builder.appName(\"NYC Taxi Analysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/Sample NYC Data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# df = df.limit(100) # Limit for testing purposes\n",
        "\n",
        "with open(\"/content/nyc-boroughs.geojson\") as f:\n",
        "    boroughs = json.load(f)\n",
        "\n",
        "# Convert borough boundaries to Shapely polygons\n",
        "borough_shapes = [(feature[\"properties\"][\"borough\"], shape(feature[\"geometry\"])) for feature in boroughs[\"features\"]]\n",
        "\n",
        "# Define UDF to find borough for a given coordinate\n",
        "def get_borough(lat, lon):\n",
        "    point = Point(lon, lat)\n",
        "    for borough, polygon in borough_shapes:\n",
        "        if polygon.contains(point):\n",
        "            return borough\n",
        "    return \"Unknown\"\n",
        "\n",
        "borough_udf = udf(get_borough, StringType())\n",
        "\n",
        "# Enrich taxi dataset with borough information\n",
        "df = df.withColumn(\"pickup_borough\", borough_udf(col(\"pickup_latitude\"), col(\"pickup_longitude\"))) \\\n",
        "       .withColumn(\"dropoff_borough\", borough_udf(col(\"dropoff_latitude\"), col(\"dropoff_longitude\")))\n",
        "\n",
        "# Convert to unix timestamp\n",
        "df = df.withColumn(\"pickup_ts\", unix_timestamp(\"pickup_datetime\", \"dd-MM-yy HH:mm\")) \\\n",
        "      .withColumn(\"dropoff_ts\", unix_timestamp(\"dropoff_datetime\", \"dd-MM-yy HH:mm\"))\n",
        "\n",
        "# Compute trip duration\n",
        "df = df.withColumn(\"trip_duration\", col(\"dropoff_ts\") - col(\"pickup_ts\"))\n",
        "\n",
        "# Remove outliers (negative duration or longer than 4 hours)\n",
        "df = df.filter((col(\"trip_duration\") > 0) & (col(\"trip_duration\") <= 14400))\n",
        "\n",
        "# Compute idle time for each taxi\n",
        "taxi_window = Window.partitionBy(\"medallion\").orderBy(\"pickup_ts\")\n",
        "df = df.withColumn(\"prev_dropoff\", lag(\"dropoff_ts\").over(taxi_window)) \\\n",
        "       .withColumn(\"idle_time\", when((col(\"pickup_ts\") - col(\"prev_dropoff\")) <= 14400, col(\"pickup_ts\") - col(\"prev_dropoff\")).otherwise(lit(0)))\n",
        "\n",
        "# Aggregate utilization per taxi\n",
        "taxi_utilization = df.groupBy(\"medallion\").agg((spark_sum(\"trip_duration\") / (spark_sum(\"trip_duration\") + spark_sum(\"idle_time\"))).alias(\"utilization\"))\n",
        "\n",
        "# Compute average time to find next fare per borough\n",
        "taxi_next_fare = df.groupBy(\"dropoff_borough\").agg(avg(\"idle_time\").alias(\"avg_time_to_next_fare\"))\n",
        "\n",
        "# Compute trip counts\n",
        "same_borough_trips = df.filter(col(\"pickup_borough\") == col(\"dropoff_borough\")).groupBy(\"pickup_borough\").agg(count(\"*\").alias(\"same_borough_trips\"))\n",
        "diff_borough_trips = df.filter(col(\"pickup_borough\") != col(\"dropoff_borough\")).groupBy(\"pickup_borough\", \"dropoff_borough\").agg(count(\"*\").alias(\"diff_borough_trips\"))\n",
        "\n",
        "# Show results – for testing purposes\n",
        "# taxi_utilization.show()\n",
        "# taxi_next_fare.show()\n",
        "# same_borough_trips.show()\n",
        "# diff_borough_trips.show()\n",
        "# total_zero_idle_time = df.filter(col(\"idle_time\") == 0).count()\n",
        "# print(total_zero_idle_time)\n",
        "\n",
        "taxi_next_fare_renamed = taxi_next_fare.withColumnRenamed(\"dropoff_borough\", \"dropoff_borough_nf\")\n",
        "\n",
        "df_final = df.select(\"medallion\", \"pickup_borough\", \"dropoff_borough\", \"trip_duration\", \"idle_time\") \\\n",
        "             .join(taxi_utilization, \"medallion\", \"left\") \\\n",
        "             .join(taxi_next_fare_renamed, df[\"dropoff_borough\"] == taxi_next_fare_renamed[\"dropoff_borough_nf\"], \"left\") \\\n",
        "             .join(same_borough_trips, \"pickup_borough\", \"left\") \\\n",
        "             .join(diff_borough_trips, [\"pickup_borough\", \"dropoff_borough\"], \"left\") \\\n",
        "             .drop(\"dropoff_borough_nf\")\n",
        "\n",
        "df_final.write.mode(\"overwrite\").parquet(\"results_parquet\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
